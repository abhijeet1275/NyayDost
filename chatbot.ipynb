{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=apikey\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_invok(system_prompt,msg):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": msg,\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "    )\n",
    "\n",
    "    return (chat_completion.choices[0].message.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1 Indemnification Obligations. Subject to the terms and conditions set out here, the indemnifying party agrees to indemnify, defend, and hold harmless the indemnified party from and against any and all damages, liabilities, losses, claims, demands, actions, lawsuits, and expenses (including without limitation reasonable attorney's fees and costs of investigation, litigation, settlement, and judgment) arising from: (i) any breach of this agreement by the indemnifying party; (ii) any grossly negligent or willful misconduct, or fraud by the indemnifying party; or (iii) any violation of applicable law by the indemnifying party arising from any third party claims, lawsuits or proceedings.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"Translate the following Hindi text to English Language. The output must be translated english text only\"\n",
    "msg = \"४.१ क्षतिपूर्ति बाध्यताएँ। यहां स्थापित शर्तों और शर्तों के अधीन, क्षतिपूर्ति करने वाले पार्टी यह सहमत होता है कि वह क्षतिपूर्ति करेगी, बचाव करेगी, और क्षतिपूर्ति प्राप्त पार्टी को नुकसान से मुक्त रखेगा, और किसी भी और सभी नुकसानों, देयताओं, क्षतियों, दावों, माँगों, कार्रवाइयों, मुकदमों और खर्चों (कम राशि के लिए वास्तविक वकील के शुल्क और जाँच, मुकदमा, निपटारे, और निर्णय के खर्च सहित) के खिलाफ जो कि इस समझौते के उल्लंघन करके, क्षतिपूर्ति करने वाले पार्टी द्वारा किया गया है; (ii) क्षतिपूर्ति करने वाले पार्टी द्वारा कोई भी गंभीर लापरवाही वाला दुराचार, या धोखाधड़ी; या (iii) क्षतिपूर्ति करने वाले पार्टी द्वारा लागू कानून का उल्लंघन करके, किसी भी तीसरे पक्ष के दावों, मुकदमों या कार्यवाहियों से उत्पन्न हो जाते हैं।\"\n",
    "\n",
    "x = llm_invok(system_prompt,msg)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = '''\n",
    "[('https://www.youtube.com/watch?v=zYxUaNyiHH8', ''), ('https://www.youtube.com/watch?v=zYxUaNyiHH8', ''), ('https://www.youtube.com/watch?v=g8d5v_NCio4', ''), ('https://www.youtube.com/watch?v=g8d5v_NCio4', ''), ('https://www.youtube.com/watch?v=9bb6AMp2__0', ''), ('https://www.youtube.com/watch?v=9bb6AMp2__0', ''), ('https://www.youtube.com/watch?v=OGq4sFSGoNM', ''), ('https://www.youtube.com/watch?v=OGq4sFSGoNM', ''), ('https://www.youtube.com/watch?v=X_yoX3PkbHE', ''), ('https://www.youtube.com/watch?v=X_yoX3PkbHE', ''), ('https://www.youtube.com/watch?v=BKmv-n0yUYc', ''), ('https://www.youtube.com/watch?v=BKmv-n0yUYc', ''), ('https://www.youtube.com/watch?v=udjcKQMAyd0', ''), ('https://www.youtube.com/watch?v=udjcKQMAyd0', ''), ('https://www.youtube.com/watch?v=mniX7-rKvHk', ''), ('https://www.youtube.com/watch?v=mniX7-rKvHk', ''), ('https://www.youtube.com/watch?v=uOto7frzrCc', ''), ('https://www.youtube.com/watch?v=uOto7frzrCc', ''), ('https://www.youtube.com/watch?v=Nq2wYlWFucg', ''), ('https://www.youtube.com/watch?v=Nq2wYlWFucg', '')]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patna High Court\n"
     ]
    }
   ],
   "source": [
    "system_prompt = 'Identify the court asked in the following text. The output must be the name of the court only.'\n",
    "msg = 'I want live recordings of patna high court.'\n",
    "\n",
    "x = llm_invok(system_prompt,msg)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = 'Below are the user query and his answer of recordings please structure the answer and give him output'\n",
    "\n",
    "msg = f\"\"\"\n",
    "User Query : I want live recordings of patna high court.\n",
    "Recordings of relevant courts link :\n",
    "{links}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Output: Sorry, No Live Recordings Found**\n",
      "\n",
      "Unfortunately, the provided information does not contain live recordings of the Patna High Court where Prasoon is being prosecuted. The given list appears to be YouTube video links with empty descriptions, which do not provide any information about the content of the videos.\n",
      "\n",
      "However, I can suggest a structured approach to find the required recordings:\n",
      "\n",
      "1. **Check Official Websites**: You can check the official website of the Patna High Court or other relevant government websites to see if they have live recordings or video archives of court proceedings.\n",
      "2. **Search YouTube**: You can try searching for the specific keywords like \"Patna High Court recordings\" or \"Prasoon court case\" on YouTube to see if any relevant videos are available.\n",
      "3. **Contact the Court**: Reach out to the Patna High Court directly and inquire about the possibility of obtaining live recordings or video recordings of the specific case.\n",
      "4. **Check with News Sources**: Look for news articles or reports that may have covered the case, they might have links to video recordings or live streams.\n",
      "\n",
      "If you have more information or context about the case, I can try to help you find the recordings.\n"
     ]
    }
   ],
   "source": [
    "x = llm_invok(system_prompt,msg)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Answer the user query\"\n",
    "msg = \"explain theory of relativity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg1 = llm_invok(system_prompt,msg)\n",
    "print(msg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\n",
    "msg = \"How is this llm model trained?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm_invok(system_prompt,msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have any specific word count information about my next response as it's generated based on user input.\n"
     ]
    }
   ],
   "source": [
    "msg= \"How many words will be there in your next response?\"\n",
    "print(llm_invok(system_prompt,msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This conversation just started. You didn't ask a previous question. What would you like to talk about?\n"
     ]
    }
   ],
   "source": [
    "msg=\"what was my previous question?\"\n",
    "print(llm_invok(system_prompt,msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 28 states and 8 Union territories in India.\n"
     ]
    }
   ],
   "source": [
    "msg = \"How many states in India\"\n",
    "print(llm_invok(system_prompt,msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"Please enter second value   77 , 73  =\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the answer, I'll add the two values: 77 + 73 = 150.\n"
     ]
    }
   ],
   "source": [
    "print(llm_invok(system_prompt,msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt= \"use the link provided here to answer the questions asked in the msg , link = 'https://njdg.ecourts.gov.in/njdg_v3/'  \"\n",
    "msg = \"what is the Number of cases of Bihar i criminal cases?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a large language model, I don't have direct access to real-time data or external links. However, I can guide you on how to find the information.\n",
      "\n",
      "You can visit the link provided (https://njdg.ecourts.gov.in/njdg_v3/) and follow these steps:\n",
      "\n",
      "1. Click on the \"State/UT\" dropdown menu and select \"Bihar\".\n",
      "2. Click on the \"Total Pending\" hyperlink.\n",
      "3. Under \"Pendency of Cases\", click on \"Criminal Cases\".\n",
      "4. Under \"Criminal Cases\" you will find the Number of cases.\n",
      "\n",
      "Please note that the exact numbers might change over time, but as of my cut-off knowledge in 2023, I couldn't find real time data to provide you exact answer.\n"
     ]
    }
   ],
   "source": [
    "print(llm_invok(system_prompt,msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"Can you find the data from this site using scraping?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can guide you on how to scrape data from this website, but the actual scraping task may require more advanced techniques due to the website's structure and potential anti-scraping measures. Here's a basic outline of how you could start scraping data from this website using Python and the `beautifulsoup4` and `requests` libraries.\n",
      "\n",
      "However, before we dive into the code, I want to acknowledge that scraping this website may be subject to certain conditions, such as:\n",
      "\n",
      "*   Checking the website's `robots.txt` file (e.g., `https://njdg.ecourts.gov.in/robots.txt`) to see if scraping is allowed.\n",
      "*   Reviewing the website's terms of service to ensure that scraping complies with their policies.\n",
      "*   Being mindful of the website's load and not sending an excessive number of requests.\n",
      "\n",
      "Here's a basic Python script that demonstrates how to fetch data from a website like the one you provided:\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "import pandas as pd\n",
      "\n",
      "def fetch_njdgpashboard_data(url):\n",
      "    try:\n",
      "        # Send a request to the website\n",
      "        response = requests.get(url)\n",
      "\n",
      "        # Check if the request was successful\n",
      "        if response.status_code != 200:\n",
      "            print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
      "            return\n",
      "\n",
      "        # Parse the HTML content using BeautifulSoup\n",
      "        soup = BeautifulSoup(response.content, 'html.parser')\n",
      "\n",
      "        # All tables on the webpage are within a table class\n",
      "        tables = soup.find_all('table')\n",
      "\n",
      "        data = []\n",
      "        for table in tables:\n",
      "            # Loop over the table rows\n",
      "            for row in table.find_all('tr'):\n",
      "                cols = row.find_all('td')\n",
      "                cols = [col.text.strip() for col in cols]\n",
      "                data.append([col for col in cols if col])  # Get td value\n",
      "\n",
      "        # Create a DataFrame from the table data\n",
      "        df = pd.DataFrame(data)\n",
      "\n",
      "        return df\n",
      "\n",
      "    except Exception as e:\n",
      "        print(f\"An error occurred: {e}\")\n",
      "        return None\n",
      "\n",
      "# Usage\n",
      "url = 'https://njdg.ecourts.gov.in/njdg_v3/'\n",
      "df = fetch_njdgpashboard_data(url)\n",
      "\n",
      "if df is not None:\n",
      "    print(df.head())\n",
      "```\n",
      "This code fetches the webpage's content and parses it using BeautifulSoup. Then, it loops over all tables on the webpage, extracts the table rows, and stores the row values in a pandas DataFrame.\n",
      "\n",
      "Keep in mind that this script might not yield the expected results due to various factors like anti-scraping measures or website dynamics.\n"
     ]
    }
   ],
   "source": [
    "print(llm_invok(system_prompt,msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in ./.venv/lib/python3.12/site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.12/site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4->bs4) (2.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install bs4\n",
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_content():\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    # print(requests.get(\"https://njdg.ecourts.gov.in/njdg_v3/\").content)\n",
    "    resp = requests.get(\"https://njdg.ecourts.gov.in/\")\n",
    "    \"\"\" print(resp.content) \"\"\"\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    \"\"\" print(soup.prettify()) \"\"\"\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NJDG-National Judicial Data Grid\n"
     ]
    }
   ],
   "source": [
    "soup = get_html_content()\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_html_content()\n",
    "system_prompt = f\"print soup\"\n",
    "msg = \"Number of Cases listed today on the website\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "\n",
    "    resp = requests.get(\"https://njdg.ecourts.gov.in/\")\n",
    "\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    script_tags = soup.find_all('script', {'type': 'text/javascript'})\n",
    "    for script in script_tags:\n",
    "        if script.string and 'Less than one year' in script.string:\n",
    "            html_content =  script.string\n",
    "            break\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    script_content = soup.get_text()\n",
    "    pending_agewise_values = re.findall(r'pendingAgewiseBarChart\\(\\s*\\'[^\\']+\\',\\s*\\'([^\\']+)\\',\\s*\\'([^\\']+)\\',', script_content)\n",
    "    if pending_agewise_values:\n",
    "        first_set = pending_agewise_values[0][0].split('~')\n",
    "        second_set = pending_agewise_values[0][1].split('~')\n",
    "\n",
    "    # Output:\n",
    "    Civil = []\n",
    "    Criminal = []\n",
    "    i=0\n",
    "    j=0\n",
    "    index = ['Less than 1 year','1-3 years','3-5 years','5-10 years','10-20 years']\n",
    "    for cases in first_set:\n",
    "        Civil.append((index[i],cases))\n",
    "        i+=1\n",
    "    for cases in second_set:\n",
    "        Criminal.append((index[j],cases))\n",
    "        j+=1\n",
    "    return Civil,Criminal\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "civil,criminal = get_data()\n",
    "\n",
    "system_prompt = f\"civil cases = {civil} criminal cases = {criminal}\"\n",
    "msg = \"Number of pending civil cases for 1-3 years\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of pending civil cases for 1-3 years is 2562460.\n"
     ]
    }
   ],
   "source": [
    "print(llm_invok(system_prompt,msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"hey chatbot give me the number of pending criminal cases for 5-10 years\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of pending criminal cases for 5-10 years is 5840498.\n"
     ]
    }
   ],
   "source": [
    "print(llm_invok(system_prompt,msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features():\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    # Make a request to the webpage\n",
    "    url = 'https://njdg.ecourts.gov.in/njdg_v3/'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the page content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Scrape all 'span' elements with the class 'h4'\n",
    "    element_a = soup.find_all('span', class_='h4')\n",
    "\n",
    "    # Loop through all elements to check if they contain an 'a' tag with an 'onclick' attribute\n",
    "    instituted_in_last_month = set()\n",
    "    disposal_in_last_month = set()\n",
    "    listed_today = set()\n",
    "    undated = set()\n",
    "    excessive_dated = set()\n",
    "    cases_filled_by_women = set()\n",
    "    cases_filled_by_senior_citizens = set()\n",
    "    contested_cases = set()\n",
    "    uncontested_cases = set()\n",
    "    for element in element_a:\n",
    "        # Check if the 'span' contains an 'a' tag\n",
    "        link = element.find('a')\n",
    "        if link and link.has_attr('onclick'):\n",
    "            # Print the 'onclick' attribute and the text inside the 'a' tag\n",
    "            if link['onclick'] == \"fetchStateData('ins',2);\":\n",
    "                instituted_in_last_month.add(('Civil' , link.text.strip()))\n",
    "            elif link['onclick'] == \"fetchStateData('ins',1);\":\n",
    "                instituted_in_last_month.add(('Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"fetchStateData('ins',3);\":\n",
    "                instituted_in_last_month.add(('Civil & Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"fetchStateData('disp',2);\":\n",
    "                disposal_in_last_month.add(('Civil' , link.text.strip()))\n",
    "            elif link['onclick'] == \"fetchStateData('disp',3);\":\n",
    "                disposal_in_last_month.add(('Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"fetchStateData('disp',1);\":\n",
    "                disposal_in_last_month.add(('Civil & Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"javascript:getAlertData('listed','2')\":\n",
    "                listed_today.add(('Civil' , link.text.strip()))\n",
    "            elif link['onclick'] == \"javascript:getAlertData('listed','3')\":\n",
    "                listed_today.add(('Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"javascript:getAlertData('listed','1')\":\n",
    "                listed_today.add(('Civil & Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"javascript:getAlertData('undated','2')\":\n",
    "                undated.add(('Civil' , link.text.strip()))\n",
    "            elif link['onclick'] == \"javascript:getAlertData('undated','3')\":\n",
    "                undated.add(('Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"javascript:getAlertData('undated','1')\":\n",
    "                undated.add(('Civil & Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"javascript:getAlertData('excessive','2')\":\n",
    "                excessive_dated.add(('Civil' , link.text.strip()))\n",
    "            elif link['onclick'] == \"javascript:getAlertData('excessive','3')\":\n",
    "                excessive_dated.add(('Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"javascript:getAlertData('excessive','1')\":\n",
    "                excessive_dated.add(('Civil & Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"fetchStateData('women',2);\":\n",
    "                cases_filled_by_women.add(('Civil' , link.text.strip()))\n",
    "            elif link['onclick'] == \"fetchStateData('women',3);\":\n",
    "                cases_filled_by_women.add(('Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"fetchStateData('women',1);\":\n",
    "                cases_filled_by_women.add(('Civil & Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"fetchStateData('citizen',2);\":\n",
    "                cases_filled_by_senior_citizens.add(('Civil' , link.text.strip()))\n",
    "            elif link['onclick'] == \"fetchStateData('citizen',3);\":\n",
    "                cases_filled_by_senior_citizens.add(('Criminal' , link.text.strip()))\n",
    "            elif link['onclick'] == \"fetchStateData('citizen',1);\":\n",
    "                cases_filled_by_senior_citizens.add(('Civil & Criminal' , link.text.strip()))  \n",
    "\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    # Loop through each table to find the span elements with class 'h4'\n",
    "    k=0\n",
    "\n",
    "    for table in tables:\n",
    "        spans = table.find_all('span', class_='h4')\n",
    "\n",
    "        for span in spans:\n",
    "            if k==21:\n",
    "                contested_cases.add(('Civil' , span.text.strip()))\n",
    "            elif k==22:\n",
    "                contested_cases.add(('Criminal' , span.text.strip()))\n",
    "            elif k==23:\n",
    "                contested_cases.add(('Civil & Criminal' , span.text.strip()))\n",
    "            elif k==24:\n",
    "                uncontested_cases.add(('Civil' , span.text.strip()))\n",
    "            elif k==25:\n",
    "                uncontested_cases.add(('Criminal' , span.text.strip()))\n",
    "            elif k==26:\n",
    "                uncontested_cases.add(('Civil & Criminal' , span.text.strip()))\n",
    "            k+=1\n",
    "    return instituted_in_last_month,disposal_in_last_month,listed_today,undated,excessive_dated,cases_filled_by_women,cases_filled_by_senior_citizens,contested_cases,uncontested_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "instituted_in_last_month,disposal_in_last_month,listed_today,undated,excessive_dated,cases_filled_by_woemn,cases_filled_by_senior_citizens,contested_cases,uncontested_cases = features()\n",
    "system_prompt = f\"instituted_in_last_month = {instituted_in_last_month} disposal_in_last_month = {disposal_in_last_month} listed_today = {listed_today} undated = {undated} excessive_dated = {excessive_dated} cases_filled_by_women = {cases_filled_by_woemn} cases_filled_by_senior_citizens = {cases_filled_by_senior_citizens} contested_cases = {contested_cases} uncontested_cases = {uncontested_cases} where civil_cases are civil cases. criminal cases are criminal cases and civil & criminal are total cases combined\"\n",
    "msg = \"How many undated cases are there in criminal cases?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16,11,861 undated cases in criminal cases.\n"
     ]
    }
   ],
   "source": [
    "print(llm_invok(system_prompt,msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"What is the number of cases listed today\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of cases listed today are: \n",
      "\n",
      "- Total (Civil & Criminal) cases: 37,498\n",
      "- Civil cases: 9,345\n",
      "- Criminal cases: 28,152\n"
     ]
    }
   ],
   "source": [
    "print(llm_invok(system_prompt,msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
